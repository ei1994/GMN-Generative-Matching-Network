## GMN-Generative-Matching-Network
**paper：Deep Generative Matching Network for Optical and SAR Image Registration（IEEE GARSS 2018已发表（7.26））**      
    [IGARSS会议论文](https://ieeexplore.ieee.org/abstract/document/8518653)    
**patent：基于深度卷积GAN的光学和SAR图像配准方法（申请号：201810276562.7）**

## 创新点：
  （1）生成网络能自动生成有标签的训练数据，不需人工标注。为保证转换的图像更接近真实图像，生成器训练时有多重约束：**对抗约束、像素级约束、重构约束。**         
	（2）数据扩充方法增加了训练样本的**数量和多样性**，满足神经网络训练的要求，提升了匹配预测网络的整体性能；  
	（3）匹配网络提取图像块对潜在的相关特征，**直接得到图像块对的匹配标签**（匹配的概率值），不需要考虑特征匹配度量的问题。
## 概述：  
  **1、** *背景：* 图像配准主要是应用在图像融合、变换检测、目标识别、跟踪等领域。对于同一场景，不同传感器从不同视角得到的异源图像，包含大量的互补信息，这对获取完整的图像信息十分有利，比如可见光和SAR图像、可见光和近红外图像，后者都能弥补前者的缺陷。成像机制不同使得**异源图像包含大量互补信息，但也造成图像结构特征的差异** ，比如图像appearances、结构、表征等，基于手工提取的特征很难度量他们的相似性，因此就想到利用CNN来挖掘学习异源图像间潜在的关系。神经网络学习需要大量的训练样本调整参数，但在遥感图像中，同一场景的异源图像较少，可直接获得的有标签的训练数据就更少了，同时人工标记样本的代价又较大。因此，**我们需要解决的关键问题就是如何获得大量的训练数据，以及所对应的标签。**    
    
  **2、** 论文采用的方案是，**使用多重约束的GAN网络学习可见光和遥感SAR图像之间的映射关系，然后利用训练好的模型扩充训练样本的数量和多样性，之后使用神经网络提取特征进行图像块的匹配预测。** 之所以想到用GAN网络增加训练样本的数量和多样性，一是，因为同一场景的异源图像较少，但不同场景的图像较多，所以就想怎么把这部分数据利用起来；二是，训练样本的人工标注成本较高，利用GAN网络可以直接得到有标签的训练数据，不需人工标注。   
    
  **3、** 具体方法是：**构建两个生成器网络，分别用于学习光学图像和遥感SAR图像之间的映射关系。** 就是生成器1将光学转换为SAR，生成器2将SAR转换为光学图像。使用有限的匹配好的异源图像数据训练这两个生成器网络，学习得到异源图像之间的映射关系，之后将一些没有匹配的光和SAR数据输入到对应的GAN中进行转换，得到对应的SAR和光学图像，从而得到大量有标签的训练数据，增加样本多样性。   
    
  **4、** 将扩充后的数据集训练**匹配网络双分支MatchNet** ，直接得到匹配标签（匹配的概率值），**不需要考虑特征匹配度量的问题**。这种数据处理方法不仅可以实现正确的配准，数据集上测试匹配率为97.2%，比MatchNet提高了7.4%，同时很显著的提高了异源配准精度，达到亚像素水平。     
    
  **5、** 创新点是怎么让生成器更好的学习异源图像之间的映射关系，生成更接近真实的训练样本图像，约束包括三个：对抗约束、像素级约束和重构约束。
重点是，为了使生成的fake图像更接近真实图像，我们使用三重约束：     
（1）**分布约束** —> 对抗损失   
（2）**像素级约束** —> mapping损失   
（3）**重构约束** —> 重构损失   

（1）对抗损失：让生成器生成的fake图片更真实，判别器无法分辨那是fake图片。
 ![](/1.PNG "对抗约束")

（2）mapping损失：让生成器生成的fake图片，在像素级别上与真实图片更接近。
 ![](/2.PNG "mapping约束")

（3）重构损失：让生成器生成的fake图片，能通过这两个生成器转换回原来的图片，该约束将两个生成器进行关联
 ![](/3.PNG "重构约束")


